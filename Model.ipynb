{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2377f03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\thevi\\Downloads\\Project\n",
      "['005' '005 percent' '005 percent inspected'\n",
      " '005 percent inspected dealer' '005 standard' '005 standard drunken'\n",
      " '005 standard drunken driving' '01' '01 03' '01 03 percent'\n",
      " '01 03 percent reduction' '01 percent' '01 percent taxpayer'\n",
      " '01 percent taxpayer people' '02' '02 04' '02 04 06' '02 pension'\n",
      " '02 pension system' '02 pension system funded' '025' '025 percent'\n",
      " '025 percent rd' '03' '03 percent']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import pickle  # Import pickle for model persistence\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Path to the new working directory (Change it to your working directory)\n",
    "new_directory = r\"C:\\Users\\thevi\\Downloads\\Project\"\n",
    "\n",
    "# Change the working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Verify the change\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_directory)\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(\"C:\\\\Users\\\\thevi\\\\Downloads\\\\Project\\\\archive\\\\train_liar.csv\")\n",
    "test_df = pd.read_csv(\"C:\\\\Users\\\\thevi\\\\Downloads\\\\Project\\\\archive\\\\test_liar.csv\")\n",
    "valid_df = pd.read_csv(\"C:\\\\Users\\\\thevi\\\\Downloads\\\\Project\\\\archive\\\\valid_liar.csv\")\n",
    "\n",
    "# Make sure the column name is correct\n",
    "column_name = 'statement'  # Adjust if the column name is different in your dataset\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Function to preprocess text data for fake news detection\n",
    "    \"\"\"\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "# Check if the column exists in the dataframe and apply preprocessing\n",
    "if column_name in train_df.columns:\n",
    "    train_df[column_name] = train_df[column_name].apply(preprocess_text)\n",
    "else:\n",
    "    print(f\"Column {column_name} not found in train dataframe.\")\n",
    "\n",
    "if column_name in test_df.columns:\n",
    "    test_df[column_name] = test_df[column_name].apply(preprocess_text)\n",
    "else:\n",
    "    print(f\"Column {column_name} not found in test dataframe.\")\n",
    "\n",
    "if column_name in valid_df.columns:\n",
    "    valid_df[column_name] = valid_df[column_name].apply(preprocess_text)\n",
    "else:\n",
    "    print(f\"Column {column_name} not found in validation dataframe.\")\n",
    "\n",
    "# TF-IDF with n-grams (including stop word removal in the preprocessing step)\n",
    "tfidf_ngram = TfidfVectorizer(ngram_range=(1,4), use_idf=True, smooth_idf=True)\n",
    "train_tfidf_ngram = tfidf_ngram.fit_transform(train_df[column_name].values)\n",
    "\n",
    "# Display some of the n-gram features\n",
    "print(tfidf_ngram.get_feature_names_out()[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e324f441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.5943939492244749\n",
      "Naive Bayes Confusion Matrix:\n",
      "[[ 581 3906]\n",
      " [ 247 5505]]\n",
      "\n",
      "Logistic Regression Accuracy: 0.6045512964857108\n",
      "Logistic Regression Confusion Matrix:\n",
      "[[1029 3458]\n",
      " [ 591 5161]]\n",
      "\n",
      "SVM Accuracy: 0.5920508194156082\n",
      "SVM Confusion Matrix:\n",
      "[[ 604 3883]\n",
      " [ 294 5458]]\n",
      "\n",
      "Random Forest Accuracy: 0.597519521708598\n",
      "Random Forest Confusion Matrix:\n",
      "[[1069 3418]\n",
      " [ 703 5049]]\n",
      "\n",
      "Decision Tree Accuracy: 0.5593315389136542\n",
      "Decision Tree Confusion Matrix:\n",
      "[[2185 2302]\n",
      " [2210 3542]]\n",
      "\n",
      "k-NN Accuracy: 0.5722242153150953\n",
      "k-NN Confusion Matrix:\n",
      "[[2119 2368]\n",
      " [2012 3740]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Preprocess and encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "Y_train = label_encoder.fit_transform(train_df['label'])\n",
    "\n",
    "# Set up stratified k-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "models = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"k-NN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "scores = {}\n",
    "trained_models = {}\n",
    "confusion_matrices = {}  # Dictionary to store confusion matrices for each model\n",
    "\n",
    "for name, model in models.items():\n",
    "    model_scores = []\n",
    "    conf_matrix = None\n",
    "\n",
    "    for train_index, val_index in kf.split(train_tfidf_ngram, Y_train):\n",
    "        X_train_kf, X_val_kf = train_tfidf_ngram[train_index], train_tfidf_ngram[val_index]\n",
    "        Y_train_kf, Y_val_kf = Y_train[train_index], Y_train[val_index]\n",
    "\n",
    "        model.fit(X_train_kf, Y_train_kf)\n",
    "        predictions = model.predict(X_val_kf)\n",
    "        score = accuracy_score(Y_val_kf, predictions)\n",
    "        model_scores.append(score)\n",
    "\n",
    "        # Compute the confusion matrix for this fold\n",
    "        current_conf_matrix = confusion_matrix(Y_val_kf, predictions)\n",
    "        conf_matrix = current_conf_matrix if conf_matrix is None else conf_matrix + current_conf_matrix\n",
    "\n",
    "    scores[name] = np.mean(model_scores)\n",
    "    confusion_matrices[name] = conf_matrix\n",
    "\n",
    "    # Save the trained model using pickle\n",
    "    with open(f\"{name}_model.pkl\", 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "# Print the average accuracy and confusion matrix for each model\n",
    "for model_name, matrix in confusion_matrices.items():\n",
    "    print(f\"{model_name} Accuracy: {scores[model_name]}\")\n",
    "    print(f\"{model_name} Confusion Matrix:\\n{matrix}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3f95556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.583008573655495\n",
      "Naive Bayes Confusion Matrix:\n",
      "[[115 500]\n",
      " [ 35 633]]\n",
      "\n",
      "Logistic Regression Accuracy: 0.6250974279033515\n",
      "Logistic Regression Confusion Matrix:\n",
      "[[262 353]\n",
      " [128 540]]\n",
      "\n",
      "SVM Accuracy: 0.6157443491816056\n",
      "SVM Confusion Matrix:\n",
      "[[212 403]\n",
      " [ 90 578]]\n",
      "\n",
      "Random Forest Accuracy: 0.6149649259547935\n",
      "Random Forest Confusion Matrix:\n",
      "[[318 297]\n",
      " [197 471]]\n",
      "\n",
      "Decision Tree Accuracy: 0.5533904910366328\n",
      "Decision Tree Confusion Matrix:\n",
      "[[306 309]\n",
      " [264 404]]\n",
      "\n",
      "k-NN Accuracy: 0.5635229929851909\n",
      "k-NN Confusion Matrix:\n",
      "[[299 316]\n",
      " [244 424]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform the test and validation datasets using the same TF-IDF vectorizer\n",
    "test_tfidf_ngram = tfidf_ngram.transform(test_df[column_name].values)\n",
    "valid_tfidf_ngram = tfidf_ngram.transform(valid_df[column_name].values)\n",
    "# Preprocess and encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "Y_train = label_encoder.fit_transform(train_df['label'])\n",
    "Y_valid = label_encoder.transform(valid_df['label'])  # Ensure labels for validation are encoded similarly\n",
    "\n",
    "models = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"k-NN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "scores = {}\n",
    "trained_models = {}\n",
    "confusion_matrices = {}  # Dictionary to store confusion matrices for each model\n",
    "\n",
    "# Fit models on the entire training set and evaluate on the validation set\n",
    "for name, model in models.items():\n",
    "    # Fit the model\n",
    "    model.fit(train_tfidf_ngram, Y_train)\n",
    "    # Save the trained model using pickle\n",
    "    with open(f\"{name}_model.pkl\", 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    predictions = model.predict(valid_tfidf_ngram)\n",
    "    score = accuracy_score(Y_valid, predictions)\n",
    "    scores[name] = score\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    conf_matrix = confusion_matrix(Y_valid, predictions)\n",
    "    confusion_matrices[name] = conf_matrix\n",
    "\n",
    "# Print the average accuracy and confusion matrix for each model\n",
    "for model_name, matrix in confusion_matrices.items():\n",
    "    print(f\"{model_name} Accuracy: {scores[model_name]}\")\n",
    "    print(f\"{model_name} Confusion Matrix:\\n{matrix}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97cf365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'C': 10, 'solver': 'liblinear'}\n",
      "Best parameters for SVM: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Logistic Regression Tuned Accuracy: 0.6212003117692907\n",
      "Logistic Regression Tuned Confusion Matrix:\n",
      "[[295 320]\n",
      " [166 502]]\n",
      "\n",
      "SVM Tuned Accuracy: 0.6219797349961029\n",
      "SVM Tuned Confusion Matrix:\n",
      "[[284 331]\n",
      " [154 514]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_train = label_encoder.fit_transform(train_df['label'])\n",
    "Y_valid = label_encoder.transform(valid_df['label'])\n",
    "\n",
    "# Setup for Logistic Regression\n",
    "with open('Logistic Regression_model.pkl', 'rb') as f:\n",
    "    logistic_model = pickle.load(f)\n",
    "\n",
    "logistic_params = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "logistic_grid = GridSearchCV(logistic_model, logistic_params, cv=5, scoring='accuracy')\n",
    "logistic_grid.fit(train_tfidf_ngram, Y_train)\n",
    "print(\"Best parameters for Logistic Regression:\", logistic_grid.best_params_)\n",
    "\n",
    "# Save the improved Logistic Regression model\n",
    "with open('Logistic_Regression_model_tuned.pkl', 'wb') as f:\n",
    "    pickle.dump(logistic_grid.best_estimator_, f)\n",
    "\n",
    "# Setup for SVM\n",
    "with open('SVM_model.pkl', 'rb') as f:\n",
    "    svm_model = pickle.load(f)\n",
    "\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "svm_grid = GridSearchCV(svm_model, svm_params, cv=5, scoring='accuracy')\n",
    "svm_grid.fit(train_tfidf_ngram, Y_train)\n",
    "print(\"Best parameters for SVM:\", svm_grid.best_params_)\n",
    "\n",
    "# Save the improved SVM model\n",
    "with open('SVM_model_tuned.pkl', 'wb') as f:\n",
    "    pickle.dump(svm_grid.best_estimator_, f)\n",
    "\n",
    "# Evaluate the improved models on the validation set\n",
    "models = {\n",
    "    \"Logistic Regression Tuned\": logistic_grid.best_estimator_,\n",
    "    \"SVM Tuned\": svm_grid.best_estimator_\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    predictions = model.predict(valid_tfidf_ngram)\n",
    "    score = accuracy_score(Y_valid, predictions)\n",
    "    conf_matrix = confusion_matrix(Y_valid, predictions)\n",
    "    print(f\"{name} Accuracy: {score}\")\n",
    "    print(f\"{name} Confusion Matrix:\\n{conf_matrix}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ce1ab70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Tuned Accuracy: 0.6216429699842022\n",
      "Logistic Regression Tuned Confusion Matrix:\n",
      "[[246 307]\n",
      " [172 541]]\n",
      "\n",
      "SVM Tuned Accuracy: 0.6153238546603476\n",
      "SVM Tuned Confusion Matrix:\n",
      "[[230 323]\n",
      " [164 549]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_tfidf_ngram = tfidf_ngram.transform(test_df[column_name].values)\n",
    "# Load the tuned Logistic Regression model\n",
    "with open('Logistic_Regression_model_tuned.pkl', 'rb') as f:\n",
    "    logistic_model_tuned = pickle.load(f)\n",
    "\n",
    "# Load the tuned SVM model\n",
    "with open('SVM_model_tuned.pkl', 'rb') as f:\n",
    "    svm_model_tuned = pickle.load(f)\n",
    "\n",
    "# Load the encoded labels for the test dataset, ensure they are properly encoded\n",
    "\n",
    "Y_test = label_encoder.transform(test_df['label']) \n",
    "\n",
    "# Initialize dictionary to store models\n",
    "models = {\n",
    "    \"Logistic Regression Tuned\": logistic_model_tuned,\n",
    "    \"SVM Tuned\": svm_model_tuned\n",
    "}\n",
    "\n",
    "# Initialize dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Evaluate each model on the test set\n",
    "for name, model in models.items():\n",
    "    predictions = model.predict(test_tfidf_ngram)\n",
    "    accuracy = accuracy_score(Y_test, predictions)\n",
    "    conf_matrix = confusion_matrix(Y_test, predictions)\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "# Print results for each model\n",
    "for model_name, result in results.items():\n",
    "    print(f\"{model_name} Accuracy: {result['accuracy']}\")\n",
    "    print(f\"{model_name} Confusion Matrix:\\n{result['confusion_matrix']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee530c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at best_logistic_regression_model.pkl\n"
     ]
    }
   ],
   "source": [
    "#We selected the tuned LR model as the main model for the Demo\n",
    "# Path where the model will be saved\n",
    "model_path = 'best_logistic_regression_model.pkl'\n",
    "\n",
    "# Save the tuned Logistic Regression model to a file\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(logistic_model_tuned, file)\n",
    "\n",
    "print(f\"Model saved successfully at {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e426c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF with n-grams (including stop word removal in the preprocessing step)\n",
    "tfidf_ngram = TfidfVectorizer(ngram_range=(1,4), use_idf=True, smooth_idf=True)\n",
    "train_tfidf_ngram = tfidf_ngram.fit_transform(train_df[column_name].values)\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_ngram, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d6aeea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
